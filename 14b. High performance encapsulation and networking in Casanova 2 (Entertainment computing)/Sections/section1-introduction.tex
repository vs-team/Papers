The video games industry is an ever growing sector with sales surpassing 20 billion dollars in 2014 \cite{game_sales_esa}. Video games are not only built for entertainment purposes, but they are also used for Edutainment, Higher Education, Health Care, Corporate, Military, Research, and other \cite{CMP_Media_2004,serious_games}. These so-called \textit{serious games} usually do not enjoy the budgets available in the entertainment industry \cite{stapleton2004serious}. Therefore, developers of serious games are interested in tools capable of overcoming the coding difficulties associated with the complexity of games, and reducing the long development times.

Video games are composed of several inter-operating components, which accomplish different and coordinated tasks, such as drawing game objects, running the physics simulation of bodies, and moving non-playable characters using artificial intelligence. These components are periodically activated in turn to update the game state and draw the scene. When game complexity increases, this leads to an increase in size and complexity of components, which, in turn, leads to an increase in the complexity of developing and maintaining them, and thus an increase of development costs.

%As the components increases their complexity and size the difficulty to develop and maintain them increases as well\footnote{Because of the nature of games O-O languages lend themselves to easily define games\cite{neubauer2002object}}. This leads to higher complexity, thus to higher amount of costs.

A possible approach to reduce development costs is to use game development tools (e.g., GameMaker, Unity3D, or UnrealEngine \cite{petridis2010engine}), which tend to produce simple games that are hard to customize and bound to a specific genre.To provide some level of customization, game developers rely on general-purpose languages (GPL's) \cite{lewis2002game}. GPL's are typically unable to provide domain-specific abstractions and constructs. This means that when developing games by means of a GPL the resulting code will be complex and expensive to maintain \cite{Rocki:2014:FAP:2554850.2555029,sujeeth2014delite}. According to \cite{beck2000extreme}, the typical life cycle of software implemented by means of a GPL is: (\textit{\textbf{i}}) \underline{building a prototype}; (\textit{\textbf{ii}}) \underline{designing} a version which code is readable and maintainable; and eventually (\textit{\textbf{iii}}) \underline{refactoring}, after obtaining confidence with the context and the problem, the code from the previous point, so as to realize the last (often non-functional) requirements. 

We can see that the just introduced cycle is applicable to game development as well: (\textit{\textbf{i}}) building a \underline{game prototype} is always necessary to take confidence with the context of the problem and the chosen tool; (\textit{\textbf{ii}}) \underline{designing game code} that is maintainable and readable requires developers to abstract the problem and to focus more on the high-level interactions of the game and its data structures. Software development techniques have been studied to improve software maintainability and tackle complexity \cite{collar2006role}. Encapsulation, which consists of isolating a set of data and operations on those data within a module and providing precise specifications for the module \cite{citeulike:10949855}, is an example of a technique aimed at increasing code maintainability and readability; and (\textit{\textbf{iii}}) \underline{refactoring} is a common process in game development, see for example the case of performance optimization, which is of high importance for games, since it is strictly connected to game smoothness, i.e., to the game's frame rate, and smoothness strongly influences the perceived quality of a game \cite{claypool2009perspectives}. Indeed developing a game is a highly dynamic process \cite{takeuchi1986new} involving a wide variety of team members with different roles, such as designers, programmers, etc. Design very often changes during the development stage, as proven in several examples from the industry, such as Starcraft, Duke Nuke'em Forever, and Final Fantasy XV \cite{variety_article}. Small changes at abstract level design translates into considerable amount of code, which might affect the overall architecture; thus every stage of the above life cycle requires effort and is time consuming. An example of this is when using encapsulation \cite{zhou2008partial} in the code. Since a game may feature many small entities, encapsulation forces those entities to interact through specific interfaces. When calling methods of the interfaces, overhead is added due to dynamic dispatching \cite{zhou2008partial}. Such overhead ultimately affects the performance of games at runtime negatively, so a complete refactoring that accommodates performance becomes necessary. Similar negative effects come from various design patterns, which all add layers of indirection. These effects impact negatively cache coherency and force CPU prediction failures \cite{albrecht2009pitfalls}. Traditional networking in games is another example that typically breaks encapsulation as the what to send over the network is dependent on the game logic; thus small changes in the game structure could affect heavily the networking layer.


What seems ideal is to have the advantages coming from both stages (\textit{ii}) and (\textit{iii}): game code that is well maintainable and readable, and at the same time with a fast run time. For this purpose, we investigated this problem and developed a solution that allows developers to write encapsulated code. Encapsulation is ``a language mechanism for restricting direct access to some of the object components.'' \cite{mitchell2003concepts}. Our solution turns, through extensive automated optimization, encapsulated code into an equivalent high-performance executable, therefore relieving developers from refactoring important design structures by hand, thus reducing the chances to make mistakes. As a further note, we want to underline that this optimization could be performed at source code level, however the logic of the program would be irremediably lost in the complex details of the architecture needed for the optimization, and thus debugging the code would be impractical.


%\noindent
To sum up, in this paper we present a solution, which makes use of optimization transformations, that addresses the problem of the loss of performance in encapsulated games and of abstracting networking primitives. We present our solution as an extension for a domain specific language for games, called ``Casanova 2'', which allows developers to write high quality games at reduced development costs. 

%\subsection{Structure of the paper}
We start with a discussion about the focus of this paper\footnote{This paper is an extended version of a conference paper that appeared as \cite{abbadi2015high}. The key additions of this journal version are: an extended related works session, and a new section on networking within the Casanova language.} and related works (Section \ref{sec:focus}). Then we start with a discussion of encapsulation and typical optimizations (which break encapsulation) and their complexity, by introducing a case study. We use the case study to identify issues in using both encapsulation and faster implementation for games (Section \ref{sec:the_problem}). We introduce our idea for dealing with encapsulation without losing performance (Section \ref{sec:idea}). We propose a specific implementation, with corresponding semantics, within the Casanova 2 language (Section \ref{sec:details}). We discuss a further extension of Casanova 2 in the domain of networking and show how the language can also provide significant improvement in productivity (Sections \ref{sec:networking} and \ref{sec:net_architecture}). We then evaluate the effectiveness of our approach in terms of performance and compactness (Section \ref{sec:evaluation}), round off with conclusions, and present future challenges within this scope (Section \ref{sec:conclusions_and_future_works}).

\section{Focus of the work and related works}
\label{sec:focus}
The focus of this paper lies exclusively within the restricted, non-general-purpose field of game development (and its sibling, real-time simulations). This greatly narrows the scope of the problem, but also severly constrains the spectrum of possible solutions. To understand this, consider that on one hand we have the deep complexity of the underlying mathematics of the physical aspects of the game and the highly concurrent nature of the discrete logic; on the other hand, we have the fundamental, pervasive non-functional requirement that no single update/draw cycle may ever take more than 1/60th of a second in total. Whereas in other soft-real-time domains one might occasionally accept a degradation of performance, provided that the variance of the distribution of computational cycles is acceptably low, the game becomes a clear failure if any frame is delayed.

This very strict performance requirement automatically excludes a large number of (admittedly beautiful and powerful) frameworks that in and of themselves would solve many architectural issues that games do need to face. This brings us to try to address the focus of the paper without tackling the general issue. We do believe that tackling the general issue of separation of concerns and real-time performance as required for games is still outside of the boundaries of what can be achieved with modern tools and as such limited work like the present paper explores an interesting direction of investigation.

The general-purpose frameworks that might be used in our present context can be classified in two broad areas: runtime dynamic machinery, and compile-time code generators.

\subsection{Runtime dynamic machinery}
Highly dynamic frameworks typically make use of mechanisms that either feature large amounts of dynamic/virtual calls, or rely on reflection. The use of dynamic/virtual calls within a big hierarchy of objects has dramatic effect on performance \cite{ungar1992object} because it severely disrupts cache coherency. This is unfortunate, as it rules out the widespread use of design patterns such as decorators, and in the functional programming world the extensive use of monads.

Reflection mechanisms (for example reflection in .NET \cite{richter2012clr}) tend to be even less effective than mechanisms with large amounts of dynamic/virtual calls , as they combine the same number of cache disruptions with the need to box/unbox everything and constantly check for the correct types of boxed arguments. Among the frameworks that use this technique, we find (\textit{i})Proxies in C\#, an aspect-oriented library supported by the .NET framework, and (\textit{ii}) netty.io, an event driven framework for networking. The overhead of these techniques makes it unfortunately very easy to exceed the maximum allotted time of 1/60th of a second per frame, or requires to dramatically reduce the number of entities processed by the game, which in turn results in a poorer game experience.


\subsection{Compile-time code generators}

A more promising venue of investigation is that of compile-time code generators, which make it possible to implement sophisticated, reusable meta-patterns such as those discussed above, but without having to rely on expensive forms of dynamism. Examples of such generators are Haskell templates, C++ templates, and macros in Lisp. The performance of these generators is clearly bound to the performance of the underlying language. As we already discussed, performance is a very strict and stringent requirement within our domain of focus, and so this immediately excludes frameworks based on languages such as Haskell or Java that have less control on performance because of large amounts of boxing (in Haskell laziness induces boxing). Other frameworks offer less disciplined meta-structures. For example, C++ templates lack a higher kinded type system that would allow us to constrain type parameters and get some measure of control on error messages. While this might seem trivial, C++ templates are very unwieldy to use and debug because the untyped replacement mechanism generates pages of errors in otherwise correct libraries only because they have been instantiated with the wrong parameters.

Moreover, hybrid frameworks, such as \textit{Treecc} (an Aspect-Oriented approach to writing compilers), force patterns on the generated code which make too much use of polymorphism. This partially defeats the point of compile-time code generators for games, as it still causes performance issues such as those outlined in \cite{ungar1992object}.

Furthermore, meta-programming approaches would bring discipline to our work, which we are actively working on improving (see Section \ref{sec:conclusions_and_future_works}).