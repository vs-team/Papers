This chapter presents the language definition and compiler architecture of Metacasanova. 


\section{Repetitive steps in compiler development}
\label{sec:ch_metacasanova_intro}
In Chapter \ref{ch:background} we gave on overview of the necessary steps involved in developing a compiler. We showed that the lexing/parsing phase is simple enough to be automated using a lexer/parser generator. Such software takes as input the grammar and the definitions of regular expressions to define the tokens of the language and produces output code containing that is able to parse a program written in a programming language defined by that grammar. However, the steps involved in the following phases, namely the \textit{type checking} and \textit{operational semantics} implementation follow a recurring pattern, but in general the behaviour of the type system and the code generation reflecting the behaviour of the operational semantics must be hard-coded in the host language in which the compiler is being implemented. Below we present two examples to show how these behaviours can be implemented in two different general purpose programming languages and show that both follow the same pattern.

\subsection{Hard-coded implementation of type rules}
As shown in Section \ref{sec:ch_background_type_checking}, type rules are expressed in the form of logical rules. Let us consider the type rules for the \texttt{if-then-else} and \texttt{while-do} statements presented in Section \ref{sec:ch_background_type_checking} in the version that assigns the type \textit{unit} to the code blocks for convenience. In a programming language that supports discriminated unions as a language abstraction (like Haskell or F\#), the syntactical element in the abstract syntax tree of the language can be expressed as

\begin{lstlisting}
type Statement =
| If of Expr * List<Statement> * List<Statement>
| While of Expr * List<Statement>
... //other statements
\end{lstlisting}

The type checking of the \texttt{if} statement requires that to check that the condition has type \texttt{bool} and that both code blocks have type \texttt{unit} (or \texttt{void}). The type checking of the \texttt{while-do} is analogous, except only one code block is used. We can then define a function \texttt{eval} that, given the environment (here we call it \textit{symbol table}) and a statement as input, returns the type given by the rule or an error if all type rules for that statement fail to correctly evaluate. For the 
\texttt{if-then-else} the implementation is the following:

\begin{lstlisting}
let rec evalStmt (symbolTable : SymbolTable) (stmt : Statement) : Type =
match stmt with
... //other statements
| If (condition,_then,_else) ->
    let conditionType = evalExpr symbolTable condition
    let thenType = evalStmt symbolTable _then
    let elseType = evalStmt symbolTable _else
    if conditionType <> Boolean then
      failwith "Invalid condition type"
    elif thenType <> Unit then
      failwith "The type of then must be unit"
    elif elseType <> Unit then
      failwith "The type of else must be unit"
    else
      Unit
... //other statements
\end{lstlisting}

\noindent
The function first executes pattern matching on the statement to identify the correct inference rule to use during the typing. It then proceeds to evaluate the premises (type of the condition and of the statement blocks) and to check their result. If all premises evaluate successfully the type contained in the conclusion is returned. Note that the function \texttt{evalExpr} is a function able to evaluate the type rule for expressions and return their type. 
The implementation of the \texttt{while-do} follows the same logic:

\begin{lstlisting}
let rec evalStmt (symbolTable : SymbolTable) (stmt : Statement) : Type =
match stmt with
... //other statements
| While (condition,_do) ->
  let conditionType = evalExpr symbolTable condition
  let doType = evalStmt symbolTable stmt
  if conditionType <> Boolean then
    failwith "Invalid condition type"
  elif doType <> Unit then
    failwith "The type of the do block must be unit"
  else
    Unit
... //other statements
\end{lstlisting}

In languages that do not provide abstractions such as discriminated unions, the type for statements must exploit polymorphism to implement the same behaviour. A statement will be represented as an interface exhibiting the behaviour of a visitor pattern:

\begin{lstlisting}
public interface Statement
{
  Type Visit(StatementVisitor visitor);
}

public interface StatementVisitor
{
  ... //other statements
  Type OnIf(Expression condition, List<Statement> _then, List<Statement> _else);
  Type OnWhile(Expression condition, List<Statement> _do);
  ... //other statements
}
\end{lstlisting}

The behaviour of the inference rule for the \texttt{if-then-else} statement is modelled by a class implementing the \texttt{StatementVisitor} interface. This class contains a method \texttt{OnIf} that implements the behaviour of the type rule itself. 

\begin{lstlisting}
public class StatementEvaluator : StatementVisitor
{
  ... //evaluation of other statements
  public Type OnIf(Expression condition, List<Statement> _then, List<Statement> _else)
  {
    Type conditionType = condition.visit(new ExpressionEvaluator());
    Type thenType = _then.Visit(new StatementEvaluator());
    Type elseType = _else.Visit(new StatementEvaluator());
    if (!conditionType.Equals(new Boolean()))
    {
      throw new TypeException("Invalid condition type");
    }
    else if (!thenType.Equals(new Unit()))
    {
      throw new TypeException("The type of then must be unit");
    }
    else if (!elseType.Equals(new Unit()))
    {
      throw new TypeException("The type of else must be unit");
    }
    else
    {
      return new Unit();
    }
  }
  
  ... //evaluation of other statements
}

public class If : Statement
{
  Expression Condition;
  List<Statement>  Then;
  List<Statement> Else;
  
  public Type Visit(StatementVisitor visitor)
  {
    return visitor.OnIf(this.Condition, this.Then, this.Else)
  }
}
\end{lstlisting}

Analogously for the \texttt{while-do} we have

\begin{lstlisting}
public class StatementEvaluator : StatementVisitor
{
  ... //evaluation of other statements
  public Type OnWhile(Expression condition, List<Statement> _do)
  {
    Type conditionType = condition.Visit(new ExpressionEvaluator());
    Type doType = _do.Visit(new StatementEvaluator());
    if (!conditionType.Equals(new Boolean()))
    {
      throw new TypeException("Invalid condition type");
    }
    else if (!doType.Equals(new Unit()))
    {
      throw new TypeException("The type of do must be unit");
    }
    else
    {
      return new Unit();
    }
  }
  ... //evaluation of other statements
}

public class While : Statement
{
  Expression Condition;
  List<Statement> Do;
  
  public Type Visit(StatementVisitor visitor)
  {
    return visitor.OnWhile(this.Condition, this.Do);
  }
}
\end{lstlisting}

\subsubsection{Generalization}
\label{sec:ch_metacasanova_inference_rule_generalization}

In general, for a node of the abstract syntax tree (AST) $\alpha$ (like \texttt{Statements}) containing syntactical structures $\sigma_{i}$ constructed with a certain amount of arguments of type $\epsilon_{\sigma_{i_1}}, ..., \epsilon_{\sigma_{i_m}}$ (such as the condition or the statement block in a control structure), the general representation of a hard-coded type rule in a language with discriminated unions is obtained by creating a union type $\alpha$ having a case $\sigma_{i}$ with arguments $\epsilon_{\sigma_{i_j}}$ for each syntactical element.

\begin{lstlisting}[mathescape = true]
type $\alpha$ =
|$\sigma_1$ of $\tau_{\sigma_{1_1}} * ... * \tau_{\sigma_{1_m}}$
...
|$\sigma_n$ of $\tau_{\sigma_{n_1}} * ... * \tau_{\sigma_{n_m}}$
\end{lstlisting}

Evaluating the inference rule through an evaluation function requires first to find out which must be applied by matching the pattern of the syntactical structure from the node of the AST. Later, we need to evaluate each of the premises with the appropriate evaluation function: if the result of each evaluation is what the rule expects (for instance, that the condition has type boolean in the \texttt{if-then-else}) then we return the result of the evaluation rule contained in the right part of the conclusion.

Let us consider a conclusion $\sigma_{j}(\epsilon_{\sigma_{j_1}} \; ... \;\epsilon_{\sigma_{j_m}})$ (where each $\epsilon$ is one of the arguments used to construct the case of the discriminate union) with a result of the evaluation $\rho_{\sigma_j}$ a set of premises $\pi_{1},...,\pi_{k}$ that are evaluated through an evaluation function $\varphi_{\pi_i}, \; i = 1,...,k$ returning a result $\rho_{\pi_i}$. Let us assume that $\rho'_{\pi_i}$ is the expected result for the premise evaluated through $\varphi_{\pi_i}$. As usual, $\Gamma$ defines the environment (symbol table). The type rule that we are trying to execute will thus have the following structure:

\begin{mathpar}
	\mprset{flushleft}
	\inferrule*
	{\Gamma \vdash \varphi_{\pi_1} \pi_1 : \rho'_{\pi_1} \\\\
	\vdots \\\\
	\Gamma \vdash \varphi_{\pi_i} \pi_i : \rho'_{\pi_i} \\\\
	\vdots\\\\
	\Gamma \vdash \varphi_{\pi_k} \pi_k : \rho'_{\pi_k}}
 {	\Gamma \vdash \sigma_{j}(\epsilon_{\sigma_{j_1}},...,\epsilon_{\sigma_{j_m}}) : \rho_{\sigma_j}} \\
\end{mathpar}

Given the considerations above, the code necessary for the evaluation will be the following:

\begin{lstlisting}[mathescape = true]
let rec $\varphi_{\sigma_j}$ $\Gamma$ $\sigma$ =
  match $\sigma$ with
  ... //other pattern matching expressions for other rules
  | $\sigma_{j}(\epsilon_{\sigma_{j_1}},...,\epsilon_{\sigma_{j_m}})$ ->
    let $\rho_{\pi_1}$ = $\varphi_{\pi_1}$ $\Gamma$ $\pi_1$
    .
    .
    .
    let $\rho_{\pi_i}$ = $\varphi_{\pi_i}$ $\Gamma$ $\pi_i$
    .
    .
    .
    let $\rho_{\pi_k}$ = $\varphi_{\pi_k}$ $\Gamma$ $\pi_k$
    if $\rho_1$ <> $\rho'_1$ then
      failwith "Type error"
    .
    .
    .
    elif $\rho_i$ <> $\rho'_i$ then
      failwith "Type error"
    .
    .
    .
    elif $\rho_m$ <> $\rho'_m$ then
      failwith "Type error"
    else
      $\rho_{\sigma_j}$    
  ... //other pattern matching expressions for other rules
\end{lstlisting}

Each evaluation function is recursive because a premise might need to run the same evaluation function (see the example of the statements above). The function contains a pattern matching that selects the correct inference rule to be used for that syntactical structure. For example, in the case of the statements, it will try to match all the possible syntactical structures for the statements and select the correct one for the input; for instance, if we are running the rule for the \texttt{if-then-else} then the pattern matching will select the match case for \texttt{if-then-else}. Note that $\gamma$ will surely be matched by one of the match cases because at this point we have a correctly generated AST after the parsing phase.

Each premise runs the appropriate evaluation function and returns a result. This result is compared with the one expected by the inference rule, and if the comparison fails the function reports a type error. If all comparisons succeed, then the result of the conclusion is returned.

In a language that does not provide discriminated unions and pattern matching the generalization is more complex: the abstract syntax tree element must be represented by an interface containing the signature of a method \texttt{Visit} used to perform an operation on a specific (polymorphic) syntactical structure. We also require the interface for the visitor pattern with the signature of the functions to run for each polymorphic instance of \texttt{Statement}. In this version we assume that the type of the result of the evaluation function for $\sigma_j$ returns a type $\tau_{\rho_{\sigma_{j}}}$ (which in the previous version could be omitted thanks to the type inference typical of functional programming languages):

\begin{lstlisting}[mathescape = true]
public interface $\alpha$
{
  public $\tau_{\sigma_j}$ Visit(Visitor visitor)
}

public interface Visitor<T>
{
  T $\varphi_{\sigma_j}(\tau_\Gamma \; \Gamma, \tau_{\sigma_{j_1}} \epsilon_{\sigma_{j_1}},...,\tau_{\sigma_{j_m}}\epsilon_{\sigma_{j_m}})$;
  ... //other statements
}
\end{lstlisting}

\noindent
Then we have to implement the visitor for the type rule for statements and a class for a specific statement:

\begin{lstlisting}[mathescape = true]
public class Evaluator : Visitor<$\tau_{\rho_{\sigma_{j}}}$>
{
  ... //evaluation of other statements
  public $\tau_{\rho_{\sigma_{j}}}$ $\varphi_{\sigma_j}(\tau_\Gamma \; \Gamma, \tau_{\sigma_{j_1}}\epsilon_{\sigma_{j_1}},...,\tau_{\sigma_{j_m}}\epsilon_{\sigma_{j_m}})$
  {
    $\tau_{\rho_{\phi_1}} \rho_{\pi_1}$ = $\varphi_{\pi_1}(\Gamma,\pi_1)$;
    .
    .
    .
    $\tau_{\rho_{\phi_i}} \rho_{\pi_i}$ = $\varphi_{\pi_i} (\Gamma,\pi_i)$;
    .
    .
    .
    $\tau_{\rho_{\phi_k}} \rho_{\pi_k}$ = $\varphi_{\pi_k}( \Gamma,\pi_k)$
    if (!$\rho_{\pi_1}$.Equals($\rho'_{\pi_1})$)
      throw new TypeError("Type error");
    .
    .
    .
    else if (!$\rho_{\pi_i}$.Equals($\rho'_{\pi_i})$)
      throw new TypeError("Type Error");
    .
    .
    .
    else if (!$\rho_{\pi_k}$.Equals($\rho'_{\pi_k})$)
      throw new TypeError("Type Error");
    else
      return new $\rho_{\sigma_j}$();
  }
  ... //evaluation of other statements
}

public $\sigma_j$ : $\alpha$
{
  $\tau_{\sigma_{j_1}} \epsilon_{\sigma_{j_1}}$;
  ...
  $\tau_{\sigma_{j_m}} \epsilon_{\sigma_{j_m}}$;
  
  public $\tau_{\rho_{\sigma_{j}}}$ Visit(Visitor<$\tau_{\rho_{\sigma_{j}}}$> visitor)
  {
    return visitor.$\varphi_{\sigma_j}$($ \epsilon_{\sigma_{j_1}},...,\epsilon_{\sigma_{j_m}}$);
  }
}
\end{lstlisting}

\subsection{Hard-coded implementation of Semantics}
As shown in Section \ref{sec:ch_background_semantics}, there are multiple ways to express the semantics of a programming language. In this work we choose to make use of the operational semantics representation to have a uniform way of expressing both the type system and the semantics of a language. Let us consider again the semantics rule for \texttt{if-then-else} and \texttt{while-do} presented in Section \ref{sec:ch_background_semantics}. The operational semantics can be implemented generating the code in the object language that emulates the behaviour of the semantics rule, in the same fashion of a type rule. This process might first pass through an intermediate language, closer to the target language. In the case of an interpreter, the behaviour of the semantics must be implemented using the abstractions available in the host language. As an example, we show a possible implementation of the semantics of the two statements mentioned above in an interpreter both in a functional programming language and in an object-oriented language, as for the type rule.

For convenience, let us make a separate rule for the semantics of a sequence of statements from the specific semantics of the control structure. Also, we introduce the statement \texttt{skip} that performs no operation

\begin{mathpar}
	\mprset{flushleft}
	\inferrule*
	{ }
	{\langle \text{skip} ; ks \rangle \Rightarrow \langle ks \rangle}
\end{mathpar}
\begin{mathpar}
	\mprset{flushleft}
	\inferrule*
	{\langle k \rangle \Rightarrow k'}
	{\langle k ; ks \rangle \Rightarrow \langle k' ; ks \rangle}
\end{mathpar}
\begin{mathpar}
	\mprset{flushleft}
	\inferrule*
	{\langle c \rangle \Rightarrow \text{\texttt{true}}}
	{\langle \text{if \textit{c} then \textit{T} else \textit{E}} \rangle \Rightarrow \text{\textit{T}}}
\end{mathpar}
\begin{mathpar}	
	\mprset{flushleft}
	\inferrule*
	{\langle c \rangle \Rightarrow \text{\texttt{false}}}
	{\langle \text{if \textit{c} then \textit{T} else \textit{E}} \rangle \Rightarrow \text{\textit{E}}}
\end{mathpar}
\begin{mathpar}	
	\mprset{flushleft}
	\inferrule*
	{\langle c \rangle \Rightarrow \text{\texttt{true}}}
	{\langle \text{while \textit{c} do \textit{L}} \rangle \Rightarrow \text{\textit{L} ; while \textit{c} do \textit{L}}}
\end{mathpar}
\begin{mathpar}	
	\mprset{flushleft}
	\inferrule*
	{\langle c \rangle \Rightarrow \text{\texttt{true}}}
	{\langle \text{while \textit{c} do \textit{L}} \rangle \Rightarrow \text{skip} }
\end{mathpar}

As for the type rules, we assume that the data type representing a statement is implemented by a discriminate union. The evaluation function first performs the pattern matching on the argument to select the correct rule to execute, in the same fashion of the type rule, but instead of analysing the types this time executes the specific behaviour of the statement, as specified by the semantics rule. For inference rules above we use the following code:

\begin{lstlisting}
let rec interpretStmt (symbolTable : SymbolTable) (stmt : Statement) : Statement =
  match stmt with
  ... //other statements semantics
  | Sequence(Skip,ks) -> interpretStmt symbolTable ks
  | Sequence(k,ks) ->
  	 let k' = interpretStmt symbolTable k
  	 interpretStmt symbolTable Sequence(k',ks)
  | If (cond,_then,_else) ->
      let condEvaluation = interpretExpr symbolTable cond
      if condEvaluation = True then
      	_then
      else
        _else
  | While (cond,_do) ->
     let condEvaluation = interpretExpr symbolTable cond
     if condEvaluation = true then
       Sequence(_do,While(cond,_do))
      else
        Skip
  ... //other statements semantics
\end{lstlisting}

As for the type evaluation, we assum that \texttt{interpretExpr} is another function that is able to process expressions and return their value. 

The function matches the kind of statement that we want to execute. In the case of a sequence of statements starting with a skip, we simply return the interpretation of the remaining part of the sequence (we indeed skip to the next statement), otherwise we have to run the first statement and then recursively evaluate the sequence formed by the result of the execution of the statement and the rest of the statements. This is needed, for instance, to correctly evaluate the body of a control structure. The body of each match case is responsible of emulating the intended behaviour described in the semantics of the control structure: the \texttt{if} returns the correct block to execute depending on the boolean value of the condition, instead the \texttt{while} returns either its body followed by the same \texttt{while} loop when the condition is \texttt{true}, otherwise \texttt{skip} to jump past the loop.

In the case of an object-oriented language, it is necessary to add a new implementation of the visitor pattern implementing the behaviour of the semantics for each statement:

\begin{lstlisting}
public class StatementInterpreter : StatementVisitor
{
  ... //other statements semantics
  public Statement OnSequence(SymbolTable symbolTable, Sequence seq)
  {
    Statement k = seq.Head;
    Statement ks = seq.Tail;
    if (k.Equals(Skip))
      return ks.Visit(new StatementInterpreter());
    else
    {
      Statement k1 = k.Visit(new StatementInterpreter());
      Statement seq1 = new Sequence(k1,ks)
      return seq1.Visit(new StatementInterpreter());
    }
  }
  public Statement OnIf(Expression cond, Statement _then, Statement _else)
  {
    Value condValue = cond.Visit(new ExpressionInterpreter());
    if (condValue.Equals(new True()))
      return _then;
    else
      return _else;
  }
  public Statement OnWhile(Expression cond, Statement _do)
  {
    Value condValue = cond.Visit(new ExpressionInterpreter());
    if (condValue.Equals(new True()))
      return new Sequence(_do,new While(cond,_do))
    else
      return new Skip();
  }
  ... //other statement semantics
}
\end{lstlisting}

A further remark is that, for the sake of simplicity, here the interpretation only returns a new statement to execute obtained by processing the current statement, but in a real application it should also return a data structure representing the state of the program.

At this point it should not be hard to observe that this pattern can be generalized as well in a way analogous to that used for type rules for both implementations, which we omit for brevity.



\subsection{Discussion}
The examples above show how the behaviour of the type checking and semantics rules must be hard-coded in the language chosen for the compiler implementation, regardless of the fact that their pattern is constantly repeated in every rule. This pattern can be captured in a meta-language that is able to process the type system and operational semantics definition of the language and produce the code to execute the behaviour of the rules. In this work we describe the meta-language for \textit{Metacasanova}, a meta-compiler that is able to read a program written in terms of type system/operational semantics rules defining a programming language, a program written in that language, and output executable code that mimics the behaviour of the semantics. Such a language relieves the programmer from writing boiler-plate code when implementing a compiler for a (Domain-Specific) language. For this reason we formulate the following research question:

\vspace{0.2cm}
\noindent
\textbf{Research question 1:} \textit{To what extent Metacasanova eases the development speed of a compiler for a Domain-Specific Language, in terms of code length compared to the hard-coded implementation, and how much does the abstraction layer of the Metacompiler affect the performance of the generated code?}

\vspace{0.2cm}
Another problem that arises when using meta-compilers is the performance decay given by the introduction of their additional abstraction layer. One of the reasons for this performance decay (see Section \ref{subsec:code_generation_discussion}) is that the meta-language (and thus the meta-type system) is unaware of the type system and the memory model of the language implemented in the meta-compiler. For this reason, checking the types and accessing the memory requires to dynamically look up a symbol table defined with the abstractions provided by the meta-language. The need for performance is for Metacasanova important because it is being used to extend the DSL for games \textit{Casanova} \cite{abbadi2015casanova, abbadithesis2017}. Thus, we formulate a second research question:

\vspace{0.2cm}
\noindent
\textbf{Research question 2:} \textit{In what way can we embed the type system of the implemented language in Metacasanova in order to get rid of the dynamic lookups at runtime and what is the performance gain of this optimization?}

\vspace{0.2cm}
We try to answer these two research questions by using a two-steps methodology: (\textit{i}) we present an architecture for Metacasanova aimed to automate the process of code generation, and then (\textit{ii}) we propose a language extension to embed the implemented language type system in the meta-type system of Metacasanova.

\subsection{Requirements of Metacasanova}
In order to relieve programmers of manually defining the behaviour described in Section \ref{sec:problem} in the back-end of the compiler, we propose the following features for Metacasanova:

\begin{itemize}
	\item It must be possible to define custom operators (or functions) and data containers. This is needed to define the syntactic structures of the language we are defining.
	\item It must be typed: each syntactic structure can be associated to a specific type in order to be able to detect meaningless terms (such as adding a string to an integer) and notify the error to the user.
	\item It must be possible to have polymorphic syntactical structures. This is useful to define equivalent ``roles'' in the language for the same syntactical structure; for instance we can say that an integer literal is both a \textit{Value} and an \textit{Arithmetic expression}.
	\item It must natively support the evaluation of semantics rules, as those shown above.
\end{itemize}

We can see that these specifications are compatible with the definition of meta-compiler, as the software takes as input a language definition written in the meta-language, a program for that language, and outputs runnable code that mimics the code that a hard-coded compiler would output.

\subsection{General overview}

A Metacasanova program is made of a set of \texttt{Data} and \texttt{Function} definitions, and a sequence of rules. A data definition specifies the constructor name of the data type (used to construct the data type), its field types, and the type name of the data. Optionally it is possible to specify a priority for the constructor of the data type. For instance this is the definition of the sum of two arithmetic expression

\begin{lstlisting}
Data Expr -> "+" -> Expr : Expr
\end{lstlisting}

\noindent
Note that Metacasanova allows you to specify any kind of notation for data types in the language syntax, depending on the order of definition of the argument types and the constructor name. In the previous example we used an infix notation. The equivalent prefix and postfix notations would be:

\begin{lstlisting}
Data "+" -> Expr -> Expr : Expr
Data Expr -> Expr -> "+" : Expr
\end{lstlisting}

\noindent
A function definition is similar to a data definition but it also has a return type. For instance the following is the evaluation function definition for the arithmetic expression above:

\begin{lstlisting}
Func "eval" -> Expr : Value
\end{lstlisting}

\noindent
In Metacasanova it is also possible to define polymorphic data in the following way:

\begin{lstlisting}
Value is Expr
\end{lstlisting}

\noindent
In this way we are saying that an atomic value is also an expression and we can pass both a composite expression and an atomic value to the evaluation function defined above.

Metacasanova also allows to embed C\# code \footnote{See Section \ref{sec:code_generation} for the motivation.} into the language by using double angular brackets. This code can be used to embed .NET types when defining data or functions, or to run C\# code in the rules. For example in the following snippets we define a floating point data which encapsulates a floating point number of .NET to be used for arithmetic computations:

\begin{lstlisting}
Data "$f" -> <<float>> : Value
\end{lstlisting}

\noindent
A rule in Metacasanova, as explained above, may contain a sequence of function calls and clauses. In the following snippet we have the rule to evaluate the sum of two floating point numbers:

\begin{lstlisting}
eval a => $f c
eval b => $f d
<<c + d>> => res
------------------------
eval (a + b) => $f res
\end{lstlisting}

\noindent
Note that if one of the two expressions does not return a floating point value, then the entire rule evaluation fails. Also note that we can embed C\# code to perform the actual arithmetic operation. Metacasanova selects a rule by means of pattern matching (in order of declaration of rules) on the function arguments. This means that both of the following rules will be valid candidates to evaluate the sum of two expressions:

\begin{lstlisting}
...
---------------
eval expr => res

...
----------------
eval (a + b) => res
\end{lstlisting} 

Finally the language supports expression bindings with the following syntax:

\begin{lstlisting}
x := $f 5
\end{lstlisting}

\begin{comment}
\subsection{Syntax in BNF}
The following is the syntax of Metacasanova in Backus-Naur form. Note that, for brevity, we omit the definitions of typical syntactical elements of programming languages, such as literals or identifiers:

\begin{lstlisting}[basicstyle = \ttfamily\tiny]
<program> ::= 
{<include>} {<import>} {<data>} <function> {<function>} {<alias>} <rule> {<rule>}
<premise> ::= 
<clause> | <functionCall> | <binding>
<binding> ::= 
id ":=" <constructor>
<rule> ::= 
{premise} "-" {"-"} <functionCall>
<clause> ::= //typical boolean expression
<functionCall> ::= 
<id> {<argument>} <arrow> <argument> | 
{<argument>} <id> {<argument>} <arrow> <argument> | 
<id> {<argument>} <arrow> <argument>
<arrow> ::= "=>" | "==>"
<constructor> ::= 
<id> {<argument>} | 
{<argument>} <id> {<argument>} | 
{<argument>} <id>
<external> ::= "<<" <csharpexpr> ">>"
<csharpexpr> ::= //all available C# expressions
<argument> ::= 
["("] 
(<id> | 
<external> | 
<literal> | 
<constructor>) 
[")"]
<literal> ::= //typical literals such as integer, float, string, ...
<import> ::= import id {"." id}
<include> ::= include id {.id}
<alias> ::= <typeDef> is <typeDef>
<typeDef> ::= id | "<<" id ">>"
<typeArguments> :: = 
'"' <id> '"' {"->" <typeDef>} ":" <typeDef> |
<typeDef> {"->" <typeDef>} "->" '"' <id> '"' {"->" <typeDef>} ":" <typeDef> |
<typeDef> {"->" typeDef} "->" '"' <id> '"' ":" <typeDef> 
<function> ::= Func <typeArguments> "=>" <typeDef> [Priority <literal>]
<data> ::= Data <typeArguments> [Priority <literal>]
\end{lstlisting}
\end{comment}

\subsection{Formalization}
In what follows we assume that the pattern matching of the function arguments in a rule succeeds, otherwise a rule will fail to return a result.
The informal semantics of the rule evaluation in Metacasanova is the following:
\begin{enumerate}
	\item[R1] A rule with no clauses or function calls always returns a result.
	\item[R2] A rule returns a result if all the clauses evaluate to \texttt{true} and all the function calls in the premise return a result.
	\item[R3] A rule fails if at least one clause evaluates to \texttt{false} or one of the function calls fails (returning no results).
\end{enumerate}
We will express the semantics, as usual, in the form of logical rules, where the conclusion is obtained when all the premises are true.
In what follows we consider a set of rules defined in the Metacasanova language $R$. Each rule has a set of function calls $F$ and a set of clauses (boolean expressions) $C$. We use the notation $f^{r}$ to express the application of the function $f$ through the rule $r$. We will define the semantics by using the notation $\langle expr \rangle$ to mark the evaluation of an expression, for example $\langle f^{r} \rangle$ means evaluating the application of $f$ through $r$. The following is the formal semantics of the rule evaluation in Metacasanova, based on the informal behaviour defined above:


\begin{mathpar}
	\mprset{flushleft}
	\inferrule*[left=R1:]
	{C = \emptyset \\\\ F = \emptyset}
	{\langle f^{r} \rangle \Rightarrow \lbrace x \rbrace} \\
	
	\mprset{flushleft}
	\inferrule*[left=R2:]
	{\forall c_{i} \in C \;, \langle c_{i} \rangle \Rightarrow true \\\\
		\forall f_{j} \in F \; , \exists r_{k} \in R \; | \; \langle f_{j}^{r_{k}} \rangle \Rightarrow \lbrace x_{r^{k}} \rbrace}
	{\langle f^{r} \rangle \Rightarrow \lbrace x_{r} \rbrace} \\
	
	\mprset{flushleft}
	\inferrule*[left=R3(a):]
	{\exists c_{i} \in C \; | \; \langle c_{i} \rangle \Rightarrow false}
	{\langle f^{r} \rangle \Rightarrow \emptyset} \\
	
	\mprset{flushleft}
	\inferrule*[left=R3(b)]
	{\forall r_{k} \in R \; , \exists f_{j} \in F \; | \; \langle f_{j}^{r_{k}} \rangle \Rightarrow \emptyset}
	{\langle f^{r} \rangle \Rightarrow \emptyset}
\end{mathpar}

R1 says that, when both $C$ and $F$ are empty (we do not have any clauses or function calls), the rule in Metacasanova returns a result. R2 says that, if all the clauses in $C$ evaluates to true and, for all the function calls in $F$ we can find a rule that returns a result (all the function applications return a result for at least one rule of the program), then the current rule returns a result. R3(a) and R3(b) specify when a rule fails to return a result: this happens when at least one of the clauses in $C$ evaluates to false, or when one of the function applications does not return a result for any of the rules defined in the program.

\vspace{0.2cm}
\noindent
In the following section we describe how the code generation process works, namely how the \texttt{Data} types of Metacasanova are mapped in the target language, and how the rule evaluation is implemented.

In Section \ref{sec:semantics} we defined the syntax and semantics of Metacasanova. In this section we explain how the abstractions of the language are compiled into the generated code. We chose C\# as target language because the development of Metacasanova started with the idea of expanding the DSL for game development Casanova with further functionalities. Casanova hard-coded compiler generated C\# code as well because it is compatible with game engines such as Unity3D and Monogame. At the same time, C\# grants decent performance without having to manually manage the memory such as for lower-level languages like C/C++. Code generation in different target languages is possible but still an ongoing project (see Section \ref{sec:conclusion}).

\section{Parsing}

\section{Type checking}

\section{Code generation}

\subsection{Data structures code generation}
The type of each data structure is generated as an interface in C\#. Each data structure defined in Metacasanova is mapped to a \texttt{class} in C\# that implements such interface. The class contains as many fields as the number of arguments the data structure contains. Each field is given an automatic name \texttt{argC} where \texttt{C} is the index of the argument in the data structure definition. The data structure symbols used in the definition might be pre-processed and replaced in order to avoid illegal characters in the C\# class definition. The class contains an additional field that stores the original name of the data structure before the replacement is performed, used for its ``pretty print''. For example the data structure

\begin{lstlisting}
Data "$i" -> int : Value
\end{lstlisting}

\noindent
will be generated as

\begin{lstlisting}
public interface Value {  }

public class __opDollari : Value
{
public string __name = "$i";
public int __arg0;

public override string ToString()
{
return "(" + __name + " " + __arg0 + ")";
}
}
\end{lstlisting}

\subsection{Code generation for rules}
Each rule contains a set of premises that in general call different functions to produce a result, and a conclusion that contains the function evaluated by the current rule and the result it produces. The code generation for the rules follows the steps below:

\begin{enumerate}
	\item Generate a data structure for each function defined in the meta-program.
	\item For each function $f$ extract all the rules whose conclusion contains $f$.
	\item Create a \texttt{switch} statement with a case for each rule that is able to execute the function (the function is in its conclusion).
	\item In the case block of each rule, define the local variables defined in the rule.
	\item Apply pattern matching to the arguments of the function contained in the conclusion of the rule. If it fails, jump immediately to the next case (rule).
	\item Store the values passed to the function call into the appropriate local variables.
	\item Run each premise by instantiating the class for the function used by it and copying the values into the input arguments.
	\item Check if the premise outputs a result and, in the case of an explicit data structure argument, check the pattern matching. If the premise result is empty or the pattern matching fails for all the possible executions of the premise then jump to the next case.
	\item Generate the result for the current rule execution. 
\end{enumerate}

\noindent
In what follows, we use as an example the code generation for the following rule (which computes the sum of two integer expressions in a programming language):

\begin{lstlisting}
eval a -> $i c
eval b -> $i d
<< c + d >> -> e
----------------
eval (a + b) -> $i e
\end{lstlisting}

From now on we will refer to an argument as \textit{explicit data argument} when its structure appears explicitly in the conclusion or in one of the premises, as in the case of \texttt{a + b} in the example above.

\subsubsection{Data structure for the function}
\label{subsubsec:function_generation}

As first step the meta-compiler generates a class for each function defined in the meta-program. This class contains one field for each argument the function accepts. It also contains a field to store the possible result of its evaluation. This field is a \texttt{struct} generated by the meta-compiler defined as follows:

\begin{lstlisting}
public struct __MetaCnvResult<T> { public T Value; public bool HasValue; }
\end{lstlisting}

The result contains a boolean to mark if the rule actually returned a result or failed, and a value which contains the result in case of success.

For example, the function

\begin{lstlisting}
Func eval -> Expr : Value
\end{lstlisting}

\noindent
will be generated as

\begin{lstlisting}
public class eval
{
public Expr __arg0;
public __MetaCnvResult<Value> __res;
...
}
\end{lstlisting}

\subsubsection{Rule execution}

The class defines a method \texttt{Run} that performs the actual code execution. The meta-compiler retrieves all the rules whose conclusion contains a call to the current function, which define all the possible ways the function can be evaluated with. It then creates a \texttt{switch} structure where each \texttt{case} represents each rule that might execute that function. The result of the rule is also initialized here (the \texttt{struct} will contain a default value and the boolean flag will be set to \texttt{false}). Each \texttt{case} defines a set of local variables, that are the variables used within the scope of that rule.

\subsubsection{Local variables definitions and pattern matching of the conclusion}

At the beginning of each \texttt{case}, the meta-compiler defines the local variables initialized with their respective default values. It also generates then the code necessary for the pattern-matching of the conclusion arguments. Since variables always pass the pattern-matching, the code is generated only for arguments explicitly defining a data structure (see the examples about arithmetic operators in Section \ref{sec:semantics}) and literals. If the pattern matching fails then the execution jumps to the next \texttt{case} (rule). For instance, the code for the following conclusion

\begin{lstlisting}
...
-------------
eval (a + b) -> $i e
\end{lstlisting}

\noindent
is generated as follows

\begin{lstlisting}
case 0:
{
Expr a = default(Expr);
Expr b = default(Expr);
int c = default(int);
int d = default(int);
int e = default(int);
if (!(__arg0 is __opPlus)) goto case 1;
...
}
\end{lstlisting}

\noindent
Note that an explicit data argument, such in the example above, might contain other nested explicit data arguments, so the pattern-matching is recursively performed on the data structure arguments themselves.

\subsubsection{Copying the input values into the local variables}
When each function is called by a premise, the local values are stored into the class fields of the function defined in Section \ref{subsubsec:function_generation}. These values must be copied to the local variables defined in the \texttt{case} block representing the rule. Particular care must be taken when one argument is an explicit data. In that case, we must copy, one by one, the content of the data into the local variables bound in the pattern matching. For example, in the rule above, we must separately copy the content of the first and second parameter of the explicit data argument into the local variables \texttt{a} and \texttt{b}. The generated code for this step, applied to the example above, will be:

\begin{lstlisting}
__opPlus __tmp0 = (__opPlus)__arg0;
a = __tmp0.__arg0;
b = __tmp0.__arg1;
\end{lstlisting}

Note that the type conversion from the polymorphic type \texttt{Expr} into \texttt{opPlus} is now safe because we have already checked during the pattern matching that we actually have \texttt{opPlus}.

\subsubsection{Generation of premises}
Before evaluating each premise, we must instantiate the class for the function that they are invoking. The input arguments of the function call must be copied into the fields of the instantiated object. If one of the arguments is an explicit data argument, then it must be instantiated and its arguments should be initialized, and then the whole data argument must be assigned to the respective function field. After this step, it is possible to invoke the \texttt{Run} method of the function to start its execution. The first premise of the example above then becomes (the generation of the second is analogous):

\begin{lstlisting}
eval a -> $i c
\end{lstlisting}

\begin{lstlisting}
eval __tmp1 = new eval();
__tmp1.__arg0 = a;
__tmp1.Run();
\end{lstlisting}

\subsubsection{Checking the premise result}
After the execution of the function called by a premise, we must check if a rule was able to correctly evaluate it. In order to do so, we must check that the result field of the function object contains a value, and if not the rule fails and we jump to the next case (rule), which is performed in the following way:

\begin{lstlisting}
if (!(__tmp1.__res.HasValue)) goto case 1;
\end{lstlisting}

If the premise was successfully evaluated by one rule, then we must check the structure of the result, which leads to the following three situations:
\begin{enumerate}
	\item The result is bound to a variable.
	\item The result is constrained to be a literal.
	\item The result is an explicit data argument.
\end{enumerate}

In the first case, as already explained above, the pattern matching always succeeds, so no check is needed. In the second case, it is enough to check the value of the literal. In the last case, all the arguments of the data argument must be checked to see if they match the expected result. In general this process is recursive, as the arguments could be themselves other explicit data arguments. If the result passes the check, then the result is copied into the local variables, in a fashion similar to the one performed for the function premise. For instance, for the premise

\begin{lstlisting}
eval a -> $i c
\end{lstlisting}

\noindent
the meta-compiler generates the following code to check the result
\begin{lstlisting}
if (!(__tmp1.__res.Value is __opDollari)) goto case 1;
__MetaCnvResult<Value> __tmp2 = __tmp1.__res;
__opDollari __tmp3 = (__opDollari)__tmp2.Value;
c = __tmp3.__arg0;
\end{lstlisting}

\subsubsection{Generation of the result}
When all premises correctly output the expected result, the rule can output the final result. In order to do that, the generated code must copy the right part of the conclusion (the result) into the \texttt{res} variable of the function class. If the right part of the conclusion is, again, an explicit data argument, then the data object must first be instantiated and then copied into the result. For example the result of the rule above is generated as follows:

\begin{lstlisting}
res = c + d;
__opDollari __tmp7 = new __opDollari();
__tmp7.__arg0 = res;
__res.HasValue = true;
__res.Value = __tmp7;
break;
\end{lstlisting}

\noindent
After this step, the rule evaluation successfully returns a result.

This implementation choice is due to the fact that we plan to support partial function applications, thus, when a function is partially applied, there is the need to store the values of the arguments that were partially given. This could still be implemented with static methods and lambdas in C\#, but not all programming languages natively support lambda abstractions, so we chose to have a set-up that allows us to change the target language without dramatically altering the logic of code generation.


